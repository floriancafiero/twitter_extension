---
title: "Twitter_extension"
author: "Florian Cafiero"
date: "09/03/2021"
output: html_document
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Importation du réseau

On isole ici les comptes Twitter ayant produit 5 tweets ou plus concernant la vaccination.

```{r import}
Sys.setlocale("LC_ALL", "fr_FR.UTF-8")
sup5_nodes <- read.csv("~/Desktop/Twitter/sup10_tweetos.csv", encoding="UTF-8", comment.char="#")
sup5_edges_glob <- read.csv("~/Desktop/Twitter/sup10_edges.csv", encoding="UTF-8", comment.char="#")
sup5_nodes <- sup5_nodes[,-1] #supprime la première colonne inutile
sup5_edges_glob <- sup5_edges_glob[,-1] #supprime la première colonne inutile
sup5_nodes <- sup5_nodes[,c(2,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32)] # On intervertit les deux premières colonnes, pour commencer par l'user_id
sup5_edges_glob <- sup5_edges_glob[,c(1,4,2,3,5,6,7)] # On se débrouille pour avoir source et target comme première et deuxième colonnes.
library(plyr)
library(dplyr)
sup5_edges <- filter(sup5_edges_glob, sup5_edges_glob[,5]!= "mention") #on filtre pour ne garder que les RT et commenté
sup5_edges <- filter(sup5_edges, sup5_edges[,5]!= "RT_comment") #on filtre pour ne garder que les RT
```

## Fusion avec BDD politique

We realize a left outer join, simply using the base R function, to merge political positioning indicators and our tweeters base.

```{r political}
political <-read.csv("~/Downloads/newest_engaged_account_unique_follower_sets_oordinates_2_3.csv")
sup5_nodes_political <- merge(sup5_nodes, political, by=c("user_id"), all.x = TRUE)
```

## Fusion avec codage quali

We realize a left outer join, simply using the base R function, to merge political positioning indicators and our tweeters base.

```{r qualit}
quali <-read.csv("~/Downloads/codage_quali_tweetos.csv", sep=";", comment.char="#")
bddfinale <- merge(sup5_nodes_political, quali, by=c("user_id"), all.x = TRUE)
bddfinale <- bddfinale[-c(38042, 44613,  44656, 45618, 45835,  46433, 46970, 46985, 47538, 47590, 47871, 48530, 49395, 49412,  49830,  50158, 50177,  50396,  50674, 50991, 51183, 51356, 51488, 51935, 52603, 52679, 52916, 53135, 53276,53493),]
names(bddfinale)[names(bddfinale) == "user"] <- "name"

n_occur <- data.frame(table(bddfinale$user_id))
n_occur[n_occur$Freq > 1,] #on vérifie l'absence de doublons
```

## Création de périodes de temps et de bases de données associées

```{r period}
library("dplyr")
sup5_edges <- filter(sup5_edges, sup5_edges[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges <- filter(sup5_edges, sup5_edges[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges <- filter(sup5_edges, sup5_edges[,1]%in% bddfinale$user_id & sup5_edges[,2] %in% bddfinale$user_id)

sup5_edges$timeperiod <- as.Date(sup5_edges$time) #on pense à bien mettre la date au format date pour permettre les comparaisons, et on se permet de négliger l'heure
sup5_edges$timeperiod = case_when(
    sup5_edges$timeperiod < "2016-06-01" ~ "avant_juin_2016",
    "2016-05-31" < sup5_edges$timeperiod & sup5_edges$timeperiod < "2017-01-01" ~ "2016_SEM2",
    "2016-12-31" < sup5_edges$timeperiod & sup5_edges$timeperiod < "2017-06-01" ~ "2017_SEM1",
    "2017-05-31" < sup5_edges$timeperiod & sup5_edges$timeperiod < "2018-01-01" ~ "2017_SEM2",
    "2017-12-31" < sup5_edges$timeperiod & sup5_edges$timeperiod < "2018-06-01" ~ "2018_SEM1",
    "2018-05-31" < sup5_edges$timeperiod & sup5_edges$timeperiod < "2019-01-01" ~ "2018_SEM2",
    "2019-01-01" < sup5_edges$timeperiod ~ "apres_janv_2019")
sup5_edges_period1 <- sup5_edges[sup5_edges$timeperiod =="2016_SEM2", ]
sup5_edges_period1 <- filter(sup5_edges_period1, sup5_edges_period1[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period1 <- filter(sup5_edges_period1, sup5_edges_period1[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period1 <- filter(sup5_edges_period1, sup5_edges_period1[,1]%in% bddfinale$user_id & sup5_edges_period1[,2] %in% bddfinale$user_id)


sup5_edges_period2 <- sup5_edges[sup5_edges$timeperiod =="2017_SEM1", ]
sup5_edges_period2 <- filter(sup5_edges_period2, sup5_edges_period2[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period2 <- filter(sup5_edges_period2, sup5_edges_period2[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period2 <- filter(sup5_edges_period2, sup5_edges_period2[,1]%in% bddfinale$user_id & sup5_edges_period2[,2] %in% bddfinale$user_id)

sup5_edges_period3 <- sup5_edges[sup5_edges$timeperiod =="2017_SEM2", ]
sup5_edges_period3 <- filter(sup5_edges_period3, sup5_edges_period3[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period3 <- filter(sup5_edges_period3, sup5_edges_period3[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period3 <- filter(sup5_edges_period3, sup5_edges_period3[,1]%in% bddfinale$user_id & sup5_edges_period3[,2] %in% bddfinale$user_id)


sup5_edges_period4 <- sup5_edges[sup5_edges$timeperiod =="2018_SEM1", ]
sup5_edges_period4 <- filter(sup5_edges_period4, sup5_edges_period4[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period4 <- filter(sup5_edges_period4, sup5_edges_period4[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period4 <- filter(sup5_edges_period4, sup5_edges_period4[,1]%in% bddfinale$user_id & sup5_edges_period4[,2] %in% bddfinale$user_id)

sup5_edges_period5 <- sup5_edges[sup5_edges$timeperiod =="2018_SEM2", ]
sup5_edges_period5 <- filter(sup5_edges_period5, sup5_edges_period5[,1]!= "NA") #on filtre les sources des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period5 <- filter(sup5_edges_period5, sup5_edges_period5[,2]!= "NA") #on filtre les destinations des liens dont l'identité n'a pas pu être  correctement crawlée
sup5_edges_period5 <- filter(sup5_edges_period5, sup5_edges_period5[,1]%in% bddfinale$user_id & sup5_edges_period5[,2] %in% bddfinale$user_id)
```

##Suprresion des isolats

```{r deleting isolates}
library(igraph)
network_vax <- graph.data.frame(sup5_edges, directed=TRUE, vertices = bddfinale)
network_vax_noiso <- delete_vertices (network_vax, V(network_vax)[degree(network_vax)==0]) # on enlève les isolats, pour ne pas les prendre en compte dans la détection de communauté etc. 
```

## Détection de communautés - Louvain non pondéré

Pour la détection de communautés, on s'assure que l'on travaille avec le minimum d'informations requise. On retire d'abord tous les doublons potentiels:

```{r removing duplicates}
library(dplyr)
sup5_edges_community <- sup5_edges[,-c(6,7,8)]
sup5_edges_community <- unique(sup5_edges_community)
network_vax_final <- graph.data.frame(sup5_edges_community, directed=TRUE, vertices = bddfinale)
network_vax_final <- delete_vertices (network_vax, V(network_vax)[degree(network_vax)==0])
```

On s'intéresse seulement au plus grands composants du réseaux, on élimine les plus petits composants (le second plus grand composant contient 12 noeuds, le 3ème noeuds, le 4ème 6 noeuds etc.).

```{r removing small components}
components_final <- components(graph = network_vax_final)
components_final
biggest_cluster_id <- which.max(components_final$csize)
vert_ids <- V(network_vax_final)[components_final$membership == biggest_cluster_id]
network_vax_final_component <- igraph::induced_subgraph(network_vax_final, vert_ids)
```

On peut ensuite lancer la détection de communautés sur le réseau global. On tente d'abord d'aplatir le réseau, sous forme de réseau non dirigé, et d'exécuter un algorithme de Louvain.

```{r undirected approximation and Louvain}
network_vax_undirected <- as.undirected(network_vax_final_component, mode = c("collapse"))
louvain_undirected <- cluster_louvain(network_vax_undirected)
sizes(louvain_undirected)
```


## Détection de communautés - Louvain pondéré


On peut choisir de pondérer les liens entre compte par le nombre de RT.

```{r finding weight}
weight <- ddply(sup5_edges,.(source_id,target_id), nrow)
weight$V1
sup5_edges_community <- left_join(sup5_edges_community, weight, by=c("source_id","target_id"))
```

On rééxecute alors l'algorithme de Louvain en intégrant au calcul le poids nouvellement créé.

```{r undirected approximation and Louvain}
network_vax_final_weighted <- graph.data.frame(sup5_edges_community, directed=TRUE, vertices = bddfinale)
network_vax_final_weighted <- delete_vertices (network_vax, V(network_vax)[degree(network_vax)==0])
components_final_weighted <- components(graph = network_vax_final_weighted)
biggest_cluster_id_w <- which.max(components_final_weighted$csize)
vert_ids_w <- V(network_vax_final_weighted)[components_final$membership == biggest_cluster_id_w]
network_vax_final_component_w <- igraph::induced_subgraph(network_vax_final_weighted, vert_ids_w)
network_vax_undirected_w <- as.undirected(network_vax_final_component_w, mode = c("collapse"))
louvain_undirected_w <- cluster_louvain(network_vax_undirected_w, weights= network_vax_undirected_w$V1 )
sizes(louvain_undirected_w)
louvain_undirected_w$membership <-recode(louvain_undirected_w$membership,
  "11" = "proscience_france",
  "52" = "mainstream_media",
  "51" = "far_left_and_protests",
  "34" = "public_health_france",
  "40" = "public_health_international",
  "22"= "conspiracy_and_far_right_france",
  "27" = "sport",
  "25" = "random",
  "46" = "conspiracy_and_far_right_international",
  "31" = "proscience_international",
  "23" = "animal_health"
)

```

On ré-attache les communautés aux noeuds dans le réseau:

```{r communities to edges}
network_vax_undirected_w$community <- louvain_undirected_w$membership
network_vax_final_component_w$community <- louvain_undirected_w$membership
```

On ré-attache les communautés aux noeuds dans la bdd des noeuds:

```{r communities to edges}
tmp <- cbind(as.data.frame(louvain_undirected_w$names), as.data.frame(louvain_undirected_w$membership))
bddfinale$community <- NA
bddfinale$community <- tmp$`louvain_undirected_w$membership`[match(bddfinale$user_id,tmp$`louvain_undirected_w$names`)]
```


## Analyse des communautés détectées

### Checking

```{r communities checking}
bddfinale_annote <- filter(bddfinale, bddfinale$PRO_ANTI_OUT!= "NA")
table_comm_pro_anti <- table (bddfinale_annote$PRO_ANTI_OUT, bddfinale_annote$community)
table_comm_pro_anti
```
On observe certains phénomènes intéressants. Tout d'abord, les classements par communauté semblent majoritairement recouvrir ceux de l'annotation. Quelques exceptions cependant: 13 critiques de la vaccination sont classés dans la communauté 11, celle des pro-science. Il s'agit en fait de "critiques", mais pas d'antivaccins, souvent issus du milieu médical (pharmacritique, docdu16, martin winckler, formindep etc) qui ne critiquent que certains aspects de la politique vaccinale (HPV, grippe notamment).

## Analyse des communautés

```{r communities analysis}
communities <- data.frame() 
for (i in unique(network_vax_final_component_w$community)) 
  { 
# create subgraphs for each community subgraph 
subgraph <- induced_subgraph(network_vax_final_component_w, v = which(network_vax_final_component_w$community == i)) 
# get size of each subgraph 
size <- igraph::gorder(subgraph) 
#sort by size
if (igraph::gorder(subgraph) > 100){
# get betweenness centrality 
btwn <- igraph::betweenness(subgraph, directed=TRUE) 
communities <- communities %>% 
  dplyr::bind_rows(data.frame(
    community= i, 
    n_members = size, 
    most_important = names(which(btwn == max(btwn))) 
    ) 
  ) 
} 
}
knitr::kable(
  communities %>% 
    dplyr::select(community, n_members, most_important)
)
```

On cherche les 5 comptes dont la centralité de degré est la plus élevée, pour chaque communauté importante détectée.

```{r communities analysis}
top_five <- data.frame() 
for (i in unique(network_vax_final_component_w$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_vax_final_component_w, v = which(network_vax_final_component_w$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree <- igraph::degree(subgraph, mode = c("in")) 
    # get top five degrees 
    top <- names(head(sort(degree, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL, username= NULL) 
  } 
  top_five <- top_five %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_five %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```

## Hubs et autorités


```{r hubs and authorities}
hs <- hub_score(network_vax_final_component_w, weights=NA)$vector
as <- authority_score(network_vax_final_component_w, weights=NA)$vector
```

```{r hubs and authorities p1}
hs_p1 <- hub_score(network_p1, weights=NA)$vector
hs_p1_top <- names(head(sort(hs_p1, decreasing = TRUE), 15)) 
write.csv(hs_p1_top, "hs_p1_top.csv")
as_p1 <- authority_score(network_p1, weights=NA)$vector
as_p1_top <- names(head(sort(as_p1, decreasing = TRUE), 15)) 
write.csv(as_p1_top, "as_p1_top.csv")
```

```{r hubs and authorities p2}
hs_p2 <- hub_score(network_p2, weights=NA)$vector
hs_p2_top <- names(head(sort(hs_p2, decreasing = TRUE), 15)) 
write.csv(hs_p2_top, "hs_p2_top.csv")
as_p2 <- authority_score(network_p2, weights=NA)$vector
as_p2_top <- names(head(sort(as_p2, decreasing = TRUE), 15)) 
write.csv(as_p2_top, "as_p2_top.csv")
```


```{r hubs and authorities p3}
hs_p3 <- hub_score(network_p3, weights=NA)$vector
hs_p3_top <- names(head(sort(hs_p3, decreasing = TRUE), 15)) 
write.csv(hs_p3_top, "hs_p3_top.csv")
as_p3 <- authority_score(network_p3, weights=NA)$vector
as_p3_top <- names(head(sort(as_p3, decreasing = TRUE), 15)) 
write.csv(as_p3_top, "as_p3_top.csv")
```

```{r hubs and authorities p4}
hs_p4 <- hub_score(network_p4, weights=NA)$vector
hs_p4_top <- names(head(sort(hs_p4, decreasing = TRUE), 15)) 
write.csv(hs_p4_top, "hs_p4_top.csv")
as_p4 <- authority_score(network_p4, weights=NA)$vector
as_p4_top <- names(head(sort(as_p4, decreasing = TRUE), 15)) 
write.csv(as_p4_top, "as_p4_top.csv")
```

```{r hubs and authorities p5}
hs_p5 <- hub_score(network_p5, weights=NA)$vector
hs_p5_top <- names(head(sort(hs_p5, decreasing = TRUE), 15)) 
write.csv(hs_p5_top, "hs_p5_top.csv")
as_p5 <- authority_score(network_p5, weights=NA)$vector
as_p5_top <- names(head(sort(as_p5, decreasing = TRUE), 15)) 
write.csv(as_p5_top, "as_p5_top.csv")
```

## Cliques

Pas très pertinent pour réseau dirigé...

```{r cliques}
cliques_max <- largest_cliques(network_vax_final_component_w)
cliques_max
```


### Variation de followers

Première question: quelles sont les variations de followers de chaque communauté, au cours de la période ? On fait une régression, en prenant comme situation de référence la communauté "out", et en ajoutant comme variable l'appartanence à chaque communauté, l'activité (nb de tweets produits), le pourcentage de RT, et le pourcentage de RT via.

On recode pour cela les communautés principales en dummy, et on élimine les NA.

```{r recoding communities as dummies}
library(fastDummies)
bddfinale <- dummy_cols(bddfinale, select_columns = 'community')
bddfinale_comm <- filter(bddfinale, bddfinale$community != "NA")
```

On réalise notre régression:

```{r followers variation}
followers_reg <- lm(bddfinale$v_followers_periode ~ bddfinale$community_proscience_france + bddfinale$community_proscience_international+  bddfinale$community_mainstream_media + bddfinale$community_far_left_and_protests + bddfinale$community_public_health_france + bddfinale$community_public_health_international + bddfinale$community_animal_health + bddfinale$community_conspiracy_and_far_right_france +  bddfinale$community_conspiracy_and_far_right_international)
summary(followers_reg)
```

On réalise ensuite notre régression en contrôlant par des paramètres d'activité:

```{r followers variation controlled}
library(jtools)
library(broom)
followers_reg_controlled <- lm(bddfinale$v_followers_periode ~ bddfinale$community_proscience_france + bddfinale$community_proscience_international+  bddfinale$community_mainstream_media + bddfinale$community_far_left_and_protests + bddfinale$community_public_health_france + bddfinale$community_public_health_international + bddfinale$community_animal_health + bddfinale$community_conspiracy_and_far_right_france +  bddfinale$community_conspiracy_and_far_right_international+ bddfinale$n_tweets_BDD + bddfinale$active_period + bddfinale$RTpercent + bddfinale$RT_via_percent + bddfinale$taux_tweets_vac + bddfinale$verified + bddfinale$N_mentions + bddfinale$n_followers)
summary(followers_reg_controlled)
plot_summs(followers_reg_controlled)
plot_coefs(followers_reg_controlled)
export_summs(followers_reg_controlled)
tidy_followers_reg_controlled <- tidy(followers_reg_controlled)
write.csv(tidy_followers_reg_controlled, "tidy_followers_reg_controlled.csv")
```

## Réseaux dirigés divisés par période

On crée des "subgraphs" pour chacune des périodes de six mois définies.  

```{r creating timperiods directed}
network_p1 <- delete.edges(network_vax_final_component_w, which(E(network_vax_final_component_w)$timeperiod!="2016_SEM2"))
network_p2 <- delete.edges(network_vax_final_component_w, which(E(network_vax_final_component_w)$timeperiod !="2017_SEM1"))
network_p3 <- delete.edges(network_vax_final_component_w, which(E(network_vax_final_component_w)$timeperiod != "2017_SEM2"))
network_p4 <- delete.edges(network_vax_final_component_w, which(E(network_vax_final_component_w)$timeperiod !="2018_SEM1"))
network_p5 <- delete.edges(network_vax_final_component_w, which(E(network_vax_final_component_w)$timeperiod !="2018_SEM2"))
```


## Analyse de l'écolution des acteurs les plus centraux (indegree) dans le graphe


```{r indegree distribution p1}
indeg <- degree(network_vax_final_component_w, mode="in")
indeg.dist.p1 <- degree_distribution(network_vax_final_component_w, cumulative=T, mode="in")
plot( x=0:max(indeg), y=1-indeg.dist.p1, pch=19, cex=1.2, col="orange",
xlab="In degree", ylab="Cumulative Frequency")
```

On cherche qui ont été les acteurs les plus centraux, et leur communauté:

```{r central p1}
degree_p1 <- igraph::degree(network_p1, mode = c("in")) 
# get top 10 degrees 
top_p1 <- names(head(sort(degree_p1, decreasing = TRUE), 15)) 
top_p1
write.csv(top_p1, "topcentral_p1.csv")
```


```{r central p2}
degree_p2 <- igraph::degree(network_p2, mode = c("in")) 
# get top 10 degrees 
top_p2 <- names(head(sort(degree_p2, decreasing = TRUE), 15)) 
top_p2
write.csv(top_p2, "topcentral_p2.csv")
```


```{r central p3}
degree_p3 <- igraph::degree(network_p3, mode = c("in")) 
# get top 10 degrees 
top_p3 <- names(head(sort(degree_p3, decreasing = TRUE), 15)) 
top_p3
write.csv(top_p3, "topcentral_p3.csv")
```


```{r central p4}
degree_p4 <- igraph::degree(network_p4, mode = c("in")) 
# get top 10 degrees 
top_p4 <- names(head(sort(degree_p4, decreasing = TRUE), 15)) 
top_p4
write.csv(top_p4, "topcentral_p4.csv")
```


```{r central p5}
degree_p5 <- igraph::degree(network_p5, mode = c("in")) 
# get top 10 degrees 
top_p5 <- names(head(sort(degree_p5, decreasing = TRUE), 15)) 
top_p5
write.csv(top_p5, "topcentral_p5.csv")
```

## Modification de la centralité au sein des communautés ?

```{r central comm p1}
top_central_p1 <- data.frame() 
for (i in unique(network_p1$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_p1, v = which(network_p1$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree_p1 <- igraph::degree(subgraph, mode = c("in")) 
    # get top fifteen indegrees 
    top <- names(head(sort(degree_p1, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL) 
  } 
  top_central_p1 <- top_central_p1 %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_central_p1 %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```


```{r central comm p2}
top_central_p2 <- data.frame() 
for (i in unique(network_p2$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_p2, v = which(network_p2$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree_p2 <- igraph::degree(subgraph, mode = c("in")) 
    # get top fifteen indegrees 
    top <- names(head(sort(degree_p2, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL) 
  } 
  top_central_p2 <- top_central_p2 %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_central_p2 %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```

```{r central comm p3}
top_central_p3 <- data.frame() 
for (i in unique(network_p3$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_p3, v = which(network_p3$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree_p3 <- igraph::degree(subgraph, mode = c("in")) 
    # get top fifteen indegrees 
    top <- names(head(sort(degree_p3, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL) 
  } 
  top_central_p3 <- top_central_p3 %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_central_p3 %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```

```{r central comm p4}
top_central_p4 <- data.frame() 
for (i in unique(network_p4$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_p4, v = which(network_p4$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree_p4 <- igraph::degree(subgraph, mode = c("in")) 
    # get top fifteen indegrees 
    top <- names(head(sort(degree_p4, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL) 
  } 
  top_central_p4 <- top_central_p4 %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_central_p4 %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```

```{r central comm p5}
top_central_p5 <- data.frame() 
for (i in unique(network_p5$community)) { 
  # create subgraphs for each community 
  subgraph <- induced_subgraph(network_p5, v = which(network_p5$community == i)) 
  # for larger communities 
  if (igraph::gorder(subgraph) > 175) { 
    # get degree 
    degree_p5 <- igraph::degree(subgraph, mode = c("in")) 
    # get top fifteen indegrees 
    top <- names(head(sort(degree_p5, decreasing = TRUE), 5))
    result <- data.frame(community = i, rank = 1:5, character = top) 
  } else { 
    result <- data.frame(community = NULL, rank = NULL, character = NULL) 
  } 
  top_central_p5 <- top_central_p5 %>% 
    dplyr::bind_rows(result) 
} 
knitr::kable(
top_central_p5 %>% 
  tidyr::pivot_wider(names_from = rank, values_from = character) 
)
```


## Activité pendant la période


Qui ont été les acteurs les plus actifs pendant ces période ?

```{r active p1-p2}

```



## Autres algorithmes de détection de communautés (ne pas exécuter en local)

Trop de communautés par défaut, on change d'algorithme, et on fixe le nombre de communautés, soit avec spinglass

```{r spinglass}
spinglass_undirected <- network_vax_undirected %>% cluster_spinglass(spins = 3)
```

Soit avec walktrap (marche sur CPU ISC):

```{r walktrap}
walk <- network_vax_undirected %>% cluster_walktrap() %>% cut_at(no = 3) 
```

Ou edge betweenness:

```{r edge betweenness}
eb <- network_vax_undirected %>% cluster_edge_betweenness() %>% cut_at(no = 3)
```

```{r infomap, echo=FALSE}
library(cluster)
infomap_global <- igraph::cluster_infomap(network_vax_final, nb.trials = 10, modularity = FALSE) 
```

```{r directed clustering, echo=FALSE}
library(DirectedClustering)
clustering_global <- ClustF(network_vax_noiso, type = "directed", isolates = "zero", norm=1)
```

```{r infomap par période, echo=FALSE}
library(cluster)
infomap_p1 <- igraph::cluster_infomap(network_vax_p1, nb.trials = 7, modularity = FALSE) 
infomap_p2 <- igraph::cluster_infomap(network_vax_p2, nb.trials = 7, modularity = FALSE)
infomap_p3 <- igraph::cluster_infomap(network_vax_p3, nb.trials = 7, modularity = FALSE)
infomap_p4 <- igraph::cluster_infomap(network_vax_p4, nb.trials = 7, modularity = FALSE)
infomap_p5 <- igraph::cluster_infomap(network_vax_p5, nb.trials = 7, modularity = FALSE)
```

## Préparation analyse de réseau réplicable

To make our computations replicable, we set an arbitrary seed.

```{r replication, echo=FALSE}
library(cluster)
library(statnet)
set.seed(12345)
statnet::update_statnet()
```

## STERGM

We use Separable Temporal Exponential family Random Graph Models (STERGM) to model the creation and destruction of links across the period. Two equations for each process are estimated.



